---
title: "Clean up Corus of Words"
author: "Eric Lehmphul"
date: "11/28/2021"
output: html_document
---

```{r}
library(tidyverse)
library(textclean)
```

```{r}
job.data <- read.csv("https://raw.githubusercontent.com/baruab/Team2_Project_3_607/main/glassdoor_datascience_updated.csv")
```

```{r}
job.data$job_description[29]
```

```{r}
job.data$job_description <- job.data$job_description %>%
  replace_non_ascii() %>%
  replace_curly_quote() %>%
  str_replace_all("[^[:graph:]]", " ") %>%
  str_replace_all("’", "") %>%
  str_replace_all("·", " ") %>%
  str_replace_all("‘", "") %>%
  str_replace_all("�", " ") %>%
  str_replace_all("—", "") %>%
  str_replace_all("   ", " ")
  
 
 
# clean.data <- function(dataframe){
#   emails <- VectorSource(dataframe$text)
#   emails <- VCorpus(emails)
#   corpus <- emails %>%
#     tm_map(removeNumbers) %>%    
#     tm_map(removePunctuation) %>% 
#     tm_map(tolower) %>% 
#     tm_map(PlainTextDocument) %>%          
#     tm_map(removeWords, stopwords("en")) %>%
#     tm_map(stripWhitespace) %>% 
#     tm_map(stemDocument)%>%
#     DocumentTermMatrix()
#   return(corpus)
# }
```

```{r}
write.csv(job.data, "glassdoor_datascience_updated.csv")
```